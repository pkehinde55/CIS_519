{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkehinde55/CIS_519/blob/main/Adaboost_ipynb_txt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs0yamHN-dY0"
      },
      "source": [
        "# **CIS 4190/5190 Homework 4 - Fall 2022**\n",
        "\n",
        "**Before starting, you must click on the \"Copy To Drive\" option in the top bar. Go to File --> Save a Copy to Drive. This is the master notebook so <u>you will not be able to save your changes without copying it </u>! Once you click on that, make sure you are working on that version of the notebook so that your work is saved**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCqibYyjERm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f500726b-bafa-4e46-a3b7-a6663dff810e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.1.5\n",
            "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "Successfully installed pandas-1.1.5\n"
          ]
        }
      ],
      "source": [
        "# Restart the runtime after running this cell everytime you open the notebook\n",
        "!pip install pandas==1.1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb-WLp5Z-cdy"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.linalg import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "np.random.seed(42)  # don't change this line\n",
        "\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2VtEzsZ-loR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893ad5bc-280e-47fc-cc93-b3c516045bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO, OK] Google Colab.\n"
          ]
        }
      ],
      "source": [
        "# For autogreader only, do not modify this cell.\n",
        "# True for Google Colab, False for autograder\n",
        "NOTEBOOK = (os.getenv('IS_AUTOGRADER') is None)\n",
        "if NOTEBOOK:\n",
        "    print(\"[INFO, OK] Google Colab.\")\n",
        "else:\n",
        "    print(\"[INFO, OK] Autograder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjjXBdEb-p8K"
      },
      "source": [
        "# **PennGrader Setup**\n",
        "First, you'll need to set up the PennGrader, an autograder we are going to use throughout the semester. The PennGrader will automatically grade your answer and provide you with an instant feedback. Unless otherwise stated, you can resubmit up to a reasonable number of attempts (e.g. 100 attemptes per day). **We will only record your latest score in our backend database**.\n",
        "\n",
        "After finishing each homework assignment, you must submit your iPython notebook to gradescope before the homework deadline. Gradescope will then retrive and display your scores from our backend database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GCTLN4G-nK2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install penngrader --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLnoPRci-sTC"
      },
      "outputs": [],
      "source": [
        "from penngrader.grader import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu0XYZHO-t8J"
      },
      "outputs": [],
      "source": [
        "#PLEASE ENSURE YOUR PENN-ID IS ENTERED CORRECTLY. IF NOT, THE AUTOGRADER WON'T KNOW WHO\n",
        "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
        "STUDENT_ID = 59331140         # YOUR PENN-ID GOES HERE AS AN INTEGER#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIDTGGbo-xkf"
      },
      "source": [
        "Run the following cell to initialize the autograder. This autograder will let you submit your code directly from this notebook and immediately get a score.\n",
        "\n",
        "**NOTE:** Remember we store your submissions and check against other student's submissions... so, not that you would, but no cheating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw_QDnZk-vvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b4c974-7770-4ae0-ad09-2854c8bba747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennGrader initialized with Student ID: 59331140\n",
            "\n",
            "Make sure this correct or we will not be able to store your grade\n"
          ]
        }
      ],
      "source": [
        "#GRADER TODO\n",
        "grader = PennGrader(homework_id = 'CIS_5190_Fall22_HW4', student_id = STUDENT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0_ydbgD0Kvf"
      },
      "outputs": [],
      "source": [
        "# Serialization code needed by the autograder\n",
        "import inspect, sys\n",
        "from IPython.core.magics.code import extract_symbols\n",
        "\n",
        "def new_getfile(object, _old_getfile=inspect.getfile):\n",
        "    if not inspect.isclass(object):\n",
        "        return _old_getfile(object)\n",
        "\n",
        "    # Lookup by parent module (as in current inspect)\n",
        "    if hasattr(object, '__module__'):\n",
        "        object_ = sys.modules.get(object.__module__)\n",
        "        if hasattr(object_, '__file__'):\n",
        "            return object_.__file__\n",
        "\n",
        "    # If parent module is __main__, lookup by methods (NEW)\n",
        "    for name, member in inspect.getmembers(object):\n",
        "        if inspect.isfunction(member) and object.__qualname__ + '.' + member.__name__ == member.__qualname__:\n",
        "            return inspect.getfile(member)\n",
        "    else:\n",
        "        raise TypeError('Source for {!r} not found'.format(object))\n",
        "inspect.getfile = new_getfile\n",
        "\n",
        "def grader_serialize(obj):\n",
        "    cell_code = \"\".join(inspect.linecache.getlines(new_getfile(obj)))\n",
        "    class_code = extract_symbols(cell_code, obj.__name__)[0][0]\n",
        "    return class_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfXK6ET2npr2"
      },
      "source": [
        "## Datasets\n",
        "Next, we will download the dataset from Google Drive to your local runtime. After successful download, you may verify that all datasets are present in your colab instance.\n",
        "\n",
        "- [observations.csv](https://drive.google.com/file/d/1RvNTrL147Cx90ABv4IfXcexaRyHB-U-e/view?usp=sharing)\n",
        "- [test_student.csv](https://drive.google.com/file/d/1EjQ3Jy5q25GaxeNKh4ahtsLgHEyW3tUj/view?usp=sharing)\n",
        "\n",
        "\n",
        "#### Acknowledgement\n",
        "Dataset obtained from kaggle.com [Hourly Weather Surface - Brazil (Southeast region)](https://www.kaggle.com/PROPPG-PPG/hourly-weather-surface-brazil-southeast-region/metadata )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dexqdaw4n3Yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573cad0b-f579-4a49-a422-7c93ec26dd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RvNTrL147Cx90ABv4IfXcexaRyHB-U-e\n",
            "To: /content/observations.csv\n",
            "100% 13.5M/13.5M [00:00<00:00, 142MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Z0I6iylDgTk2OKuKDaQVR9I1aJvgRsn_\n",
            "To: /content/test_student.csv\n",
            "100% 277k/277k [00:00<00:00, 69.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "if NOTEBOOK:\n",
        "  import gdown\n",
        "  if not os.path.exists(\"observations.csv\"):\n",
        "    !gdown --id 1RvNTrL147Cx90ABv4IfXcexaRyHB-U-e\n",
        "  if not os.path.exists(\"test_student.csv\"):\n",
        "    !gdown --id 1Z0I6iylDgTk2OKuKDaQVR9I1aJvgRsn_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GdHHkKWlXSX"
      },
      "source": [
        "#### **NOTE 1. If you are running into a `__builtins__' error, it's likely because you're using a function call of the form numpy.ndarray.mean(), like a.mean(). This does not play nice with PennGrader unfortunately. Please use the function call numpy.mean(a) instead.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5aRm2cWbgxD"
      },
      "source": [
        "# **1. [20 pts] Data preprocessing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEtfpvmx-bJs"
      },
      "source": [
        "This is the data preprocessing part of the homework. We will be focusing on a dataset of Brazilian weather station observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYAXZbY_Wo4o"
      },
      "source": [
        "## **1.1. Importing the dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1PCOKsv_5mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a9e083-2c15-4efc-c53a-bd52c839766d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   wsid                 mdct  prcp    stp   smax   smin  gbrd  temp  dewp  \\\n",
            "0   178  2007-11-06 00:00:00   NaN  982.5  982.5  981.3   NaN  29.3  12.1   \n",
            "1   178  2007-11-06 01:00:00   NaN  983.2  983.2  982.5   NaN  29.0  13.5   \n",
            "2   178  2007-11-06 02:00:00   NaN  983.5  983.5  983.2   NaN  27.4  14.0   \n",
            "3   178  2007-11-06 03:00:00   NaN  983.7  983.7  983.4   NaN  25.8  16.9   \n",
            "4   178  2007-11-06 04:00:00   NaN  983.7  983.8  983.6   NaN  25.4  16.4   \n",
            "\n",
            "   tmax  dmax  tmin  dmin  hmdy  hmax  hmin  wdsp   wdct  gust  \n",
            "0  29.7  16.8  25.5  10.8  35.0  58.0  32.0   3.2  101.0   6.5  \n",
            "1  29.9  13.6  29.0  12.2  39.0  39.0  35.0   3.6   94.0   6.4  \n",
            "2  29.0  14.0  27.4  13.6  44.0  44.0  39.0   2.5   93.0   6.9  \n",
            "3  27.4  16.9  25.8  14.1  58.0  58.0  44.0   1.7   96.0   5.8  \n",
            "4  26.3  17.0  25.3  16.4  57.0  58.0  56.0   3.1  110.0   7.5  \n"
          ]
        }
      ],
      "source": [
        "if NOTEBOOK:\n",
        "    df = pd.read_csv(\"observations.csv\")\n",
        "    df = df.drop([\"Unnamed: 0\"], axis=1)\n",
        "    print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Oh6P-FAA1GY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe97318-b1c5-4734-c055-42a52587cb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122000, 19)\n"
          ]
        }
      ],
      "source": [
        "#Check that this outputs the data frame with 122000 rows and 19 columns\n",
        "if NOTEBOOK:\n",
        "    print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4f1XfY0W7YJ"
      },
      "source": [
        "## **1.2. [20 pts] Data preprocessing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG4GdAu-I1jF"
      },
      "source": [
        "### **1.2.1. [2 pts]**\n",
        "\n",
        "First let us start by converting the \"mdct\" column from the weather dataset into a datetime. Look into to_datetime() function in pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfADjpbUXUdY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7811f00f-f38a-4683-f02b-84acc929bb68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        wsid                mdct  prcp    stp   smax   smin      gbrd  temp  \\\n",
              "0        178 2007-11-06 00:00:00   NaN  982.5  982.5  981.3       NaN  29.3   \n",
              "1        178 2007-11-06 01:00:00   NaN  983.2  983.2  982.5       NaN  29.0   \n",
              "2        178 2007-11-06 02:00:00   NaN  983.5  983.5  983.2       NaN  27.4   \n",
              "3        178 2007-11-06 03:00:00   NaN  983.7  983.7  983.4       NaN  25.8   \n",
              "4        178 2007-11-06 04:00:00   NaN  983.7  983.8  983.6       NaN  25.4   \n",
              "...      ...                 ...   ...    ...    ...    ...       ...   ...   \n",
              "121995   423 2011-05-09 11:00:00   NaN  929.1  929.1  928.6   229.705  16.2   \n",
              "121996   423 2011-05-09 12:00:00   NaN  929.7  929.9  929.1   565.674  18.0   \n",
              "121997   423 2011-05-09 13:00:00   NaN  929.6  929.7  929.5  1578.380  20.6   \n",
              "121998   423 2011-05-09 14:00:00   NaN  929.4  929.8  929.4  1113.874  21.2   \n",
              "121999   423 2011-05-09 15:00:00   NaN  929.1  929.4  929.0  1697.740  21.6   \n",
              "\n",
              "        dewp  tmax  dmax  tmin  dmin  hmdy  hmax  hmin  wdsp   wdct  gust  \n",
              "0       12.1  29.7  16.8  25.5  10.8  35.0  58.0  32.0   3.2  101.0   6.5  \n",
              "1       13.5  29.9  13.6  29.0  12.2  39.0  39.0  35.0   3.6   94.0   6.4  \n",
              "2       14.0  29.0  14.0  27.4  13.6  44.0  44.0  39.0   2.5   93.0   6.9  \n",
              "3       16.9  27.4  16.9  25.8  14.1  58.0  58.0  44.0   1.7   96.0   5.8  \n",
              "4       16.4  26.3  17.0  25.3  16.4  57.0  58.0  56.0   3.1  110.0   7.5  \n",
              "...      ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   ...  \n",
              "121995  14.6  16.2  14.9  14.3  13.4  90.0  94.0  90.0   0.7  244.0   2.4  \n",
              "121996  15.8  18.0  15.8  15.8  14.4  87.0  93.0  87.0   0.9  198.0   2.8  \n",
              "121997  16.0  21.2  16.9  18.0  15.3  75.0  87.0  72.0   2.2  149.0   5.7  \n",
              "121998  16.5  21.2  16.7  20.1  15.9  75.0  79.0  74.0   2.9  181.0   7.1  \n",
              "121999  16.4  22.3  17.2  21.0  15.8  72.0  76.0  68.0   2.1  153.0   5.7  \n",
              "\n",
              "[122000 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38d593d9-1e66-40ff-b37a-9c6a710bdb4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsid</th>\n",
              "      <th>mdct</th>\n",
              "      <th>prcp</th>\n",
              "      <th>stp</th>\n",
              "      <th>smax</th>\n",
              "      <th>smin</th>\n",
              "      <th>gbrd</th>\n",
              "      <th>temp</th>\n",
              "      <th>dewp</th>\n",
              "      <th>tmax</th>\n",
              "      <th>dmax</th>\n",
              "      <th>tmin</th>\n",
              "      <th>dmin</th>\n",
              "      <th>hmdy</th>\n",
              "      <th>hmax</th>\n",
              "      <th>hmin</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>wdct</th>\n",
              "      <th>gust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>178</td>\n",
              "      <td>2007-11-06 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>982.5</td>\n",
              "      <td>982.5</td>\n",
              "      <td>981.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.3</td>\n",
              "      <td>12.1</td>\n",
              "      <td>29.7</td>\n",
              "      <td>16.8</td>\n",
              "      <td>25.5</td>\n",
              "      <td>10.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>101.0</td>\n",
              "      <td>6.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>178</td>\n",
              "      <td>2007-11-06 01:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>983.2</td>\n",
              "      <td>983.2</td>\n",
              "      <td>982.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>29.9</td>\n",
              "      <td>13.6</td>\n",
              "      <td>29.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>39.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>94.0</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>178</td>\n",
              "      <td>2007-11-06 02:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>983.5</td>\n",
              "      <td>983.5</td>\n",
              "      <td>983.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>13.6</td>\n",
              "      <td>44.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>93.0</td>\n",
              "      <td>6.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>178</td>\n",
              "      <td>2007-11-06 03:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>983.7</td>\n",
              "      <td>983.7</td>\n",
              "      <td>983.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.8</td>\n",
              "      <td>16.9</td>\n",
              "      <td>27.4</td>\n",
              "      <td>16.9</td>\n",
              "      <td>25.8</td>\n",
              "      <td>14.1</td>\n",
              "      <td>58.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>96.0</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>178</td>\n",
              "      <td>2007-11-06 04:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>983.7</td>\n",
              "      <td>983.8</td>\n",
              "      <td>983.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.4</td>\n",
              "      <td>16.4</td>\n",
              "      <td>26.3</td>\n",
              "      <td>17.0</td>\n",
              "      <td>25.3</td>\n",
              "      <td>16.4</td>\n",
              "      <td>57.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>110.0</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121995</th>\n",
              "      <td>423</td>\n",
              "      <td>2011-05-09 11:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>929.1</td>\n",
              "      <td>929.1</td>\n",
              "      <td>928.6</td>\n",
              "      <td>229.705</td>\n",
              "      <td>16.2</td>\n",
              "      <td>14.6</td>\n",
              "      <td>16.2</td>\n",
              "      <td>14.9</td>\n",
              "      <td>14.3</td>\n",
              "      <td>13.4</td>\n",
              "      <td>90.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>244.0</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121996</th>\n",
              "      <td>423</td>\n",
              "      <td>2011-05-09 12:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>929.7</td>\n",
              "      <td>929.9</td>\n",
              "      <td>929.1</td>\n",
              "      <td>565.674</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>15.8</td>\n",
              "      <td>14.4</td>\n",
              "      <td>87.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>198.0</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121997</th>\n",
              "      <td>423</td>\n",
              "      <td>2011-05-09 13:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>929.6</td>\n",
              "      <td>929.7</td>\n",
              "      <td>929.5</td>\n",
              "      <td>1578.380</td>\n",
              "      <td>20.6</td>\n",
              "      <td>16.0</td>\n",
              "      <td>21.2</td>\n",
              "      <td>16.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>75.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>149.0</td>\n",
              "      <td>5.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121998</th>\n",
              "      <td>423</td>\n",
              "      <td>2011-05-09 14:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>929.4</td>\n",
              "      <td>929.8</td>\n",
              "      <td>929.4</td>\n",
              "      <td>1113.874</td>\n",
              "      <td>21.2</td>\n",
              "      <td>16.5</td>\n",
              "      <td>21.2</td>\n",
              "      <td>16.7</td>\n",
              "      <td>20.1</td>\n",
              "      <td>15.9</td>\n",
              "      <td>75.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>181.0</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121999</th>\n",
              "      <td>423</td>\n",
              "      <td>2011-05-09 15:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>929.1</td>\n",
              "      <td>929.4</td>\n",
              "      <td>929.0</td>\n",
              "      <td>1697.740</td>\n",
              "      <td>21.6</td>\n",
              "      <td>16.4</td>\n",
              "      <td>22.3</td>\n",
              "      <td>17.2</td>\n",
              "      <td>21.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>153.0</td>\n",
              "      <td>5.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122000 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38d593d9-1e66-40ff-b37a-9c6a710bdb4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38d593d9-1e66-40ff-b37a-9c6a710bdb4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38d593d9-1e66-40ff-b37a-9c6a710bdb4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if NOTEBOOK:\n",
        "    # STUDENT TODO: Convert the data type of the `mcdt` column in df to datetime\n",
        "    df[\"mdct\"]= pd.to_datetime(df[\"mdct\"])\n",
        "    display(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZMAPpn1THFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2511177-d6f7-493c-ad59-09dc6cead0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 2/2 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_datetime', answer = df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPlibce4n-S9"
      },
      "source": [
        "### **1.2.2. [4 pts]**\n",
        "\n",
        "1.   Replace the missing values in the columns `gust, gbrd, wdsp, dewp, dmin, dmax` with 0.\n",
        "\n",
        "2. Drop the rows where temp is 0.\n",
        "\n",
        "3. Drop the column `prcp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfjA9VRkoZn8"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "    # STUDENT TODO:\n",
        "    #Replace the missing values in the columns gust, gbrd, wdsp, dewp, dmin, dmax with 0.\n",
        "    df['gust'] = df['gust'].fillna(0)\n",
        "    df['gbrd'] = df['gbrd'].fillna(0)\n",
        "    df['wdsp'] = df['wdsp'].fillna(0)\n",
        "    df['dewp'] = df['dewp'].fillna(0)\n",
        "    df['dmin'] = df['dmin'].fillna(0)\n",
        "    df['dmax'] = df['dmax'].fillna(0)\n",
        "\n",
        "    df.drop(df[(df['temp'] == 0)].index, inplace=True)\n",
        "    #drop column\n",
        "    df.drop(\"prcp\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjuuge2GBqRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71af37ca-0c67-42bf-e191-9dd2e0d421df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 4/4 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_remove', answer = df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkiR5_lPpQmz"
      },
      "source": [
        "### **1.2.3. [10 pts]**\n",
        "\n",
        "We want to calculate the difference in each metric over 1 hour. So basically if the temperature goes from 19.4 at 1200 hrs to 19.1 at 1300 hrs on a certain date we want the value to be -0.3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f93mlhWWwAVB"
      },
      "source": [
        "Create two copies of the dataframe and shift the datetime by +1 hour on the right copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UWYKMRswAdW"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "    import datetime\n",
        "    # STUDENT TODO:\n",
        "    left_df = df.copy()\n",
        "    right_df = df.copy()\n",
        "    # Add 1 hour\n",
        "    right_df[\"mdct\"] = right_df[\"mdct\"] + pd.Timedelta(hours=1)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcRF416coWCX"
      },
      "source": [
        "1. Perform a left join between `left_df` and `right_df` on the `wsid` and `mcdt` columns. In the `merged_df` retain only the rows which have values from both `left_df` and `right_df`. (Clue: set `indicator` to be `True` while performing the merge and filter using the `_merge` column in the `merged_df`)\n",
        "\n",
        "Understand how `merged_df` looks like using `.head(), .describe(), .info(), etc.` before proceeding further.\n",
        "\n",
        "2. For the variables `stp, smax, smin, gbrd, dewp, tmax, dmax, tmin, dmin, hmdy, hmax, hmin, wdsp, wdct, gust, temp` (stored in the `columns` list), subtract the \"_y\" columns from their corresponding \"_x\" columns. For example, you should be subtracting `stp_y` column from the `stp_x` column in merged_df.\n",
        "\n",
        "3. Store each of these subtraction results in a new column in `merged_df`. For example, store the result of `merged_df[\"stp_x\"] - merged_df[\"stp_y\"]` in `merged_df[\"stp\"]`.\n",
        "\n",
        "```\n",
        "merged_df[\"stp\"] = merged_df[\"stp_x\"] - merged_df[\"stp_y\"]\n",
        "```\n",
        "\n",
        "> Do this for all the variables in `columns`.\n",
        "\n",
        "4. Drop the columns with \"_x\" and \"_y\" in their name from `merged_df`.\n",
        "\n",
        "5. Drop the columns `['_merge', 'mdct', 'wsid']` from `merged_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6y0Ne2lofbL"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "    columns = [\"stp\", \"smax\", \"smin\", \"gbrd\", \"dewp\", \"tmax\",\n",
        "               \"dmax\", \"tmin\", \"dmin\", \"hmdy\", \"hmax\",\n",
        "               \"hmin\", \"wdsp\", \"wdct\", \"gust\", \"temp\"]\n",
        "\n",
        "    # STUDENT TODO:\n",
        "    # Left join\n",
        "    merged_df = pd.merge(left_df,right_df, on=['wsid','mdct'] , indicator = True, how='left')\n",
        "    #Filter to rows with both left and right key values\n",
        "    merged_df = merged_df[merged_df['_merge'] == 'both']\n",
        "\n",
        "    for columnName in columns:\n",
        "      merged_df[columnName] = merged_df[columnName + \"_x\"] - merged_df[columnName + \"_y\"]\n",
        "      merged_df.drop(columnName + \"_x\", axis=1, inplace=True)\n",
        "      merged_df.drop(columnName + \"_y\", axis=1, inplace=True)\n",
        "\n",
        "    merged_df.drop(\"_merge\", axis=1, inplace=True)\n",
        "    merged_df.drop(\"mdct\", axis=1, inplace=True)\n",
        "    merged_df.drop(\"wsid\", axis=1, inplace=True)\n",
        "\n",
        "    #display(merged_df)\n",
        "\n",
        "\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohBRyxPOB66V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe26269-73fa-4bfe-9c47-7e7d0efa523e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 10/10 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_shift', answer = merged_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RmOwYxMz6Va"
      },
      "source": [
        "### **1.2.4. [4 pts]**\n",
        "\n",
        "We have created a copy of `merged_df` for you (`final_cleaned_df`).\n",
        "\n",
        "1. Replace any negative `temp` value (`temp` < 0) in `final_cleaned_df` with 0.\n",
        "2. Replace any non-negative `temp` value (`temp` >= 0) in `final_cleaned_df` with 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rnanafi14Nn"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "    final_cleaned_df = merged_df.copy()\n",
        "    # STUDENT TODO:\n",
        "    final_cleaned_df.loc[final_cleaned_df[\"temp\"] >= 0, \"temp\"] = 1\n",
        "    final_cleaned_df.loc[final_cleaned_df[\"temp\"] < 0, \"temp\"] = 0\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQN4pLanw7fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO-aV5PNChDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e705a138-97fc-4b11-b46e-3af30b610355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 4/4 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_temp', answer = final_cleaned_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz_bGjWTOewG"
      },
      "source": [
        "# **2. [25 pts] AdaBoost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgUBn3BX9ol"
      },
      "source": [
        "## **2.1.  [3 pts] Logistic regression with sample weights**\n",
        "\n",
        "As you will have learnt from the lectures, AdaBoost fits weak learners (here, logistic regression model)  in each iteration, to a dataset with weights $w_i$ attached to each sample $(x_i, y_i)$. The loss function now becomes:\n",
        "\n",
        "> $\n",
        "\\mathcal{L}({\\theta}) = -\\sum_{i =1}^N w_{i} \\times [ y_i\\log(h_{{\\theta}}({x}_i)) + (1 - y_i)\\log(1 - h_{{\\theta}}({x}_i))]\n",
        "$\n",
        "\n",
        "where $h_\\theta(x)$ is the logistic regression hypothesis function.\n",
        "\n",
        "The gradient of this weighted loss function with respect to the weight $\\theta_j$ is given by:\n",
        "\n",
        "> $\\frac{\\partial \\mathcal{L}({\\theta})}{\\partial \\theta_j} = \\sum_{i=1}^{N}w_{i}(h_{{\\theta}}({x}_i) - y_i)x_{ij}$\n",
        "\n",
        "Using this information, complete the `compute_gradient` method in the `LogisticRegression` class to account for sample weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpa6o-m5hS0T"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1PEAbJ7-Q4r"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    \"\"\"\n",
        "    Logistic Regression (aka logit, MaxEnt) classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha: float, default=0.1\n",
        "        Learning rate\n",
        "    tol : float, default=0.01\n",
        "        Tolerance for stopping criteria\n",
        "    max_iter : int, default=1000\n",
        "        Maximum number of iterations of gradient descent\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    theta_ : numpy.ndarray of shape (D + 1,)\n",
        "        The value of the coefficients after gradient descent has converged\n",
        "        or the number of iterations hit the maximum limit\n",
        "    converged_: boolean\n",
        "        Boolean value indicating whether gradient descent converged or not\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.1, tol=0.01, max_iter=1000):\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "        self.theta_ = None\n",
        "        self.converged_ = False\n",
        "\n",
        "    def compute_gradient(self, theta, X, y, sample_weight):\n",
        "        \"\"\"\n",
        "        Compute the gradient of the cost function.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        theta: numpy.ndarray of shape (D + 1,)\n",
        "            The coefficients\n",
        "        X: numpy.ndarray of shape (N, D + 1)\n",
        "            The features matrix\n",
        "        y: numpy.ndarray of shape (N,)\n",
        "            The target variable array\n",
        "        sample_weight: numpy.ndarray of shape (N,)\n",
        "            The sample weight array\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        gradient: numpy.ndarray of shape (D + 1,)\n",
        "            The gradient values\n",
        "        \"\"\"\n",
        "\n",
        "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "        y_hat = sigmoid(X.dot(theta))\n",
        "\n",
        "        # STUDENT TODO: Compute the gradient\n",
        "        #print(X.shape)\n",
        "        #print(y.shape)\n",
        "        #print(sample_weight.shape)\n",
        "        #display(X)\n",
        "        #display(y)\n",
        "        #display(sample_weight)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # If I call the vector sample_weight * (y_hat - y) W\n",
        "        # Then I want to multiply the ith column of X by the ith entry in the N by 1 vector W\n",
        "        return np.transpose(X).dot(sample_weight * (y_hat - y))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # STUDENT TODO END\n",
        "\n",
        "    def fit(self, X, y, sample_weight):\n",
        "        \"\"\"\n",
        "        Compute the coefficients using gradient descent and store them as theta_.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (N, D)\n",
        "            The features matrix\n",
        "        y: numpy.ndarray of shape (N,)\n",
        "            The target variable array\n",
        "        sample_weight: numpy.ndarray of shape (N,)\n",
        "            The sample weight array\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Nothing\n",
        "        \"\"\"\n",
        "\n",
        "        N, D = X.shape\n",
        "\n",
        "        # Adding a column of ones at the beginning for the bias term\n",
        "        ones_col = np.ones((N, 1))\n",
        "        X = np.hstack((ones_col, X))\n",
        "\n",
        "        # Initializing the weights\n",
        "        theta_old = np.zeros((D + 1,))\n",
        "        theta_new = theta_old.copy()\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            theta_new = theta_old - self.alpha * self.compute_gradient(theta_old, X, y, sample_weight)\n",
        "\n",
        "            if np.linalg.norm(theta_new - theta_old) / (np.linalg.norm(theta_old) + self.tol) <= self.tol:\n",
        "                self.converged_ = True\n",
        "                break\n",
        "\n",
        "            theta_old = theta_new.copy()\n",
        "\n",
        "        self.theta_ = theta_new\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict the probabilities that the data points in X belong to class 1.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (N, D)\n",
        "            The features matrix\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_hat: numpy.ndarray of shape (N,)\n",
        "            The predicted probabilities that the data points in X belong to class 1\n",
        "        \"\"\"\n",
        "\n",
        "        N = X.shape[0]\n",
        "\n",
        "        # Adding a column of ones at the beginning for the bias term\n",
        "        ones_col = np.ones((N, 1))\n",
        "        X = np.hstack((ones_col, X))\n",
        "\n",
        "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "        y_hat = sigmoid(X.dot(self.theta_))\n",
        "        return y_hat\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the classes of the data points in X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (N, D)\n",
        "            The features matrix\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: numpy.ndarray of shape (N,)\n",
        "            The predicted class of the data points in X\n",
        "        \"\"\"\n",
        "\n",
        "        y_hat = self.predict_proba(X)\n",
        "        y_pred = y_hat.copy()\n",
        "        y_pred[y_pred >= 0.5] = 1\n",
        "        y_pred[y_pred < 0.5] = 0\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMnnQw5BVv-J"
      },
      "source": [
        "### Test case for the `compute_gradient` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWn_IBKZ9NWv"
      },
      "outputs": [],
      "source": [
        "def test_compute_gradient(StudentLogisticRegression):\n",
        "\n",
        "    student_lr_clf = StudentLogisticRegression()\n",
        "    np.random.seed(0)\n",
        "    theta_tc = np.random.randn(2)\n",
        "    X_tc = np.random.randn(100, 2)\n",
        "    y_tc = np.random.randint(0, 2, 100)\n",
        "    sample_weight_tc = np.random.uniform(0, 1, 100)\n",
        "    student_ans = student_lr_clf.compute_gradient(theta_tc, X_tc, y_tc, sample_weight_tc)\n",
        "    required_ans = np.array([12.903225675830651, -1.0829605960182223])\n",
        "\n",
        "    assert np.linalg.norm(student_ans - required_ans) < 1e-2 * required_ans.size\n",
        "\n",
        "if NOTEBOOK:\n",
        "    test_compute_gradient(LogisticRegression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNfmQsI99Rgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103028fc-c7db-40a0-c384-7d8213c85c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_compute_gradient_autograder', answer = grader_serialize(LogisticRegression))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTuNHGX35ulA"
      },
      "source": [
        "## **2.2. [20 pts] AdaBoostClassifier Implementation**\n",
        "\n",
        "In this section, you will be implementing the AdaBoost classifier with the logistic regression weak learner from above.\n",
        "\n",
        "### **2.2.1. [12 pts] Follow the hints in the `fit` method in the `AdaBoostClassifier` class to implement the following algorithm.**\n",
        "\n",
        "Use the following Adaboost pseudocode as a reference.\n",
        "\n",
        "**INPUT:**\n",
        "\n",
        "1. training data $X, y = \\{(x_{i}, y_{i})\\}_{i=1}^N$\n",
        "\n",
        "2. number of iterations $T$\n",
        "\n",
        "**ALGORITHM:**\n",
        "\n",
        "1.   Initialize $N$ uniform weights, i.e., $w_{1} = [1/N, 1/N, ..., 1/N]$\n",
        "\n",
        "2.   `For` $t = 1, 2, ... T$:\n",
        "\n",
        "> 2.1. Train model $h_t$ on $X$ and $y$ with instance weights $w_{t}$\n",
        "\n",
        "> 2.2. Compute the weighted training error rate of $h_{t}$: $\\epsilon_{t} = \\sum_{i: y_i \\ne h_t(x_i)} w_{t,i}$\n",
        "\n",
        "> 2.3. If $\\epsilon_{t} > 0.5$, flip $h_t$'s predictions\n",
        "\n",
        "> 2.4. Set $\\beta_{t} = \\frac{1}{2}\\text{ln}\\left(\\frac{1 - \\epsilon_t}{\\epsilon_t}\\right)$\n",
        "\n",
        "> 2.5. Update all instance weights: $w_{t + 1,i} = w_{t,i}\\times\\text{exp}(-\\beta_{t}y_{i}h_{t}(x_{i}))$ $\\forall i = 1, 2, ..., N$\n",
        "\n",
        "> 2.6. Normalize $w_{t+1}$ such that the elements sum to 1\n",
        "\n",
        "> `End For`\n",
        "\n",
        "### **2.2.2. [8 pts] Follow the hints in the `predict` method in the `AdaBoostClassifier` class for obtaining the predictions of the trained AdaBoost classifier.**\n",
        "\n",
        "> $H(x) = \\text{sign}\\left(\\sum_{t=1}^{T}\\beta_{t}h_{t}(x)\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-ep_MeohVZM"
      },
      "outputs": [],
      "source": [
        "class AdaBoostClassifier:\n",
        "    \"\"\"\n",
        "    AdaBoost classifier based on logistic regression\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    T: int, default=100\n",
        "        The number of logistic regression models in the boosting model\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    beta_arr_ : list of length T\n",
        "        The list of beta values in the boosting model\n",
        "\n",
        "    h_arr_: list of length T\n",
        "        The list of logistic regression models in the boosting model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T=100):\n",
        "\n",
        "        self.T = T\n",
        "\n",
        "        self.beta_arr_ = []\n",
        "        self.h_arr_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Train the logistic regression models (h) and compute their coefficients (beta),\n",
        "        and store them in h_arr_ and beta_arr_ respectively.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (N, D)\n",
        "            The features matrix\n",
        "        y: numpy.ndarray of shape (N,)\n",
        "            The target variable array\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Nothing\n",
        "        \"\"\"\n",
        "\n",
        "        N = X.shape[0]\n",
        "\n",
        "        # STUDENT TODO: Initialize w with appropriate values\n",
        "        #Initialize  𝑁  uniform weights, i.e.,  𝑤1=[1/𝑁,1/𝑁,...,1/𝑁]\n",
        "        w = np.full(N, 1/N)\n",
        "\n",
        "\n",
        "        # STUDENT TODO END\n",
        "\n",
        "        y_ = y.copy()\n",
        "        # STUDENT TODO: Update y_ such that the 0's in y_ are replaced by -1\n",
        "        y_[y_ == 0] = -1\n",
        "        # STUDENT TODO END\n",
        "\n",
        "        for t in range(self.T):\n",
        "            h = LogisticRegression()\n",
        "\n",
        "            # STUDENT TODO: Fit h to X and y using w as the sample weights\n",
        "            h.fit(X, y,w)\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            # STUDENT TODO: Obtain the predictions from h and compute epsilon\n",
        "            y_pred = h.predict(X)\n",
        "\n",
        "            #1 is in y_match if we have the right prediction\n",
        "            #y_match = np.abs(y_pred - y)\n",
        "            #epsilon = np.dot(w, y_match)\n",
        "            weights_of_incorrect_predictions = w[y != y_pred]\n",
        "            epsilon = np.sum(weights_of_incorrect_predictions)\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            # STUDENT TODO: If epsilon > 0.5:\n",
        "            # 1. flip the predictions, i.e., replace 1's with 0's and 0's with 1's\n",
        "            # 2. invert the model (h), i.e., make it predict 1 for what it predicted 0 earlier and vice-versa (clue: think about modifying h.theta_)\n",
        "            if epsilon > 0.5:\n",
        "              y_pred[y_pred == 0] = -1\n",
        "              y_pred[y_pred == 1] = 0\n",
        "              y_pred[y_pred == -1] = 1\n",
        "              h.theta_ = - h.theta_\n",
        "\n",
        "\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            self.h_arr_.append(h)\n",
        "\n",
        "            if epsilon == 0:\n",
        "                beta = np.inf\n",
        "                self.beta_arr_.append(beta)\n",
        "                break\n",
        "\n",
        "            # STUDENT TODO: Compute beta\n",
        "            beta = 0.5 * np.log((1.0 - epsilon) / (epsilon))\n",
        "\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            self.beta_arr_.append(beta)\n",
        "\n",
        "            y_pred_ = y_pred.copy()\n",
        "\n",
        "            # STUDENT TODO: Update y_pred_ such that the 0's in y_pred_ are replaced by -1\n",
        "            y_pred_[y_pred_== 0] = -1\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            # STUDENT TODO: Update w and normalize it such that the values in w sum to 1\n",
        "            w *= np.exp(-beta * y_ * y_pred_)\n",
        "            # Normalize to one\n",
        "            w /= np.sum(w)\n",
        "\n",
        "            # STUDENT TODO END\n",
        "        print(self.beta_arr_)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the classes of the data points in X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (N, D)\n",
        "            The features matrix\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred: numpy.ndarray of shape (N,)\n",
        "            The predicted class of the data points in X\n",
        "        \"\"\"\n",
        "\n",
        "        N = X.shape[0]\n",
        "\n",
        "        # Initialize the summation of beta times h for each x_i\n",
        "        sum_beta_times_h = np.zeros((N,))\n",
        "\n",
        "        for t in range(len(self.h_arr_)):\n",
        "\n",
        "            # STUDENT TODO: Obtain the predictions of the t-th model in self.h_arr_\n",
        "            # Replace the 0's in the array with -1\n",
        "            h = self.h_arr_[t]\n",
        "            pred = h.predict(X)\n",
        "            pred[pred == 0] = -1\n",
        "            # STUDENT TODO END\n",
        "\n",
        "            # STUDENT TODO: Update sum_beta_times_h\n",
        "            sum_beta_times_h += self.beta_arr_[t] * pred\n",
        "            # STUDENT TODO END\n",
        "\n",
        "        # STUDENT TODO: Create an array `y_pred` for the final predictions\n",
        "        # Fill 0's and 1's in `y_pred` depending on the sum_beta_time_h value in the corresponding location\n",
        "        y_pred = np.zeros(N)\n",
        "        y_pred[sum_beta_times_h > 0] = 1\n",
        "        y_pred[sum_beta_times_h < 0] = 0\n",
        "\n",
        "        return y_pred\n",
        "        # STUDENT TODO END\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EICaCxuHUY2j"
      },
      "source": [
        "### Test case for the `fit` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w30orkoA8w5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba383567-6c86-40db-da2a-bcffdfddaca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08017132503758954, 0.046732864002838985, 0.02280800817970769, 0.07012335626140594]\n"
          ]
        }
      ],
      "source": [
        "def test_adaboost_fit(StudentAdaBoostClassifier):\n",
        "\n",
        "    T = 4\n",
        "    N = 100\n",
        "    D = 2\n",
        "\n",
        "    student_ab_clf = StudentAdaBoostClassifier(T=T)\n",
        "    np.random.seed(0)\n",
        "    X_tc = np.random.randn(N, D)\n",
        "    y_tc = np.random.randint(0, 2, N)\n",
        "    student_ab_clf.fit(X_tc, y_tc)\n",
        "\n",
        "    beta_arr_student_ans = student_ab_clf.beta_arr_\n",
        "    beta_arr_required_ans = np.array([0.08017132503758954, 0.046732864002838985,\n",
        "                                      0.022808008179707476, 0.07012335626140642])\n",
        "    assert np.linalg.norm(beta_arr_student_ans - beta_arr_required_ans) < 1e-2 * beta_arr_required_ans.size\n",
        "\n",
        "    h_arr_student_ans = np.zeros([T, D + 1])\n",
        "\n",
        "    for indx, h in enumerate(student_ab_clf.h_arr_):\n",
        "        h_arr_student_ans[indx] = h.theta_\n",
        "\n",
        "    h_arr_required_ans = np.array([[-0.01514967, -0.01713051,  0.21344566],\n",
        "                                   [-0.01738886, -0.00656722,  0.12035635],\n",
        "                                   [-0.0132557,  -0.00428943, 0.06616284],\n",
        "                                   [-0.01037174, -0.00334141,  0.03943088]])\n",
        "\n",
        "    assert np.linalg.norm(h_arr_student_ans - h_arr_required_ans) < 1e-2 * h_arr_required_ans.size\n",
        "\n",
        "if NOTEBOOK:\n",
        "    test_adaboost_fit(AdaBoostClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u89ffT3LWtLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d57f597-d096-46be-faf7-ba4c9a073a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 12/12 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_adaboost_fit_autograder', answer = (grader_serialize(LogisticRegression), grader_serialize(AdaBoostClassifier)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6NG8KfQUg1c"
      },
      "source": [
        "### Test case for the `predict` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGB1aPLgWtfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f9f638-9516-4f67-8172-d05d180f434f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08017132503758954, 0.046732864002838985, 0.02280800817970769, 0.07012335626140594]\n",
            "[1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "def test_adaboost_predict(StudentAdaBoostClassifier):\n",
        "\n",
        "    T = 4\n",
        "    N = 100\n",
        "    D = 2\n",
        "\n",
        "    student_ab_clf = StudentAdaBoostClassifier(T=T)\n",
        "    np.random.seed(0)\n",
        "    X_tc = np.random.randn(N, D)\n",
        "    y_tc = np.random.randint(0, 2, N)\n",
        "    student_ab_clf.fit(X_tc, y_tc)\n",
        "\n",
        "    student_ans = student_ab_clf.predict(X_tc)\n",
        "    print(student_ans)\n",
        "    required_ans = [1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
        "                    0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
        "                    1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
        "                    0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
        "                    1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]\n",
        "\n",
        "    assert np.mean(student_ans == required_ans) >= 0.98\n",
        "\n",
        "if NOTEBOOK:\n",
        "    test_adaboost_predict(AdaBoostClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pixKpOEbXxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfadb37c-8f46-44fa-ce0a-9e7b3257b17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 8/8 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_adaboost_predict_autograder', answer = (grader_serialize(LogisticRegression), grader_serialize(AdaBoostClassifier)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sFtGKi_WQBm"
      },
      "source": [
        "## **2.3. [2 pts] AdaBoost on the dataset**\n",
        "\n",
        "Follow the hints in the `adaboost_on_dataset` method in the below cell to run `AdaBoostClassifier` on the dataset you prepared in section 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwXKNBEiYPX3"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "    test_df = pd.read_csv(\"test_student.csv\").drop(columns=[\"Unnamed: 0\"])\n",
        "\n",
        "def adaboost_on_dataset():\n",
        "    \"\"\"\n",
        "    Trains the AdaBoostClassifier on a real-world dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Nothing\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y_test_pred: numpy.ndarray\n",
        "        The predicted classes of the datapoints in test_df\n",
        "    \"\"\"\n",
        "\n",
        "    # STUDENT TODO START: Initialize X_train and y_train with appropriate values (clue: use .iloc followed by .values of the DataFrame class)\n",
        "    display(test_df)\n",
        "    X_train = final_cleaned_df.iloc[:, :-1].values\n",
        "    y_train = final_cleaned_df.iloc[:, -1].values\n",
        "\n",
        "    #X = test_df.iloc[:, :-1].values\n",
        "   # y = test_df.iloc[:, -1].values\n",
        "\n",
        "    # STUDENT TODO END\n",
        "\n",
        "    # STUDENT TODO START: Initialize X_test\n",
        "  #  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    X_test = test_df\n",
        "\n",
        "\n",
        "    # STUDENT TODO END\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    # STUDENT TODO START: Scale the features of X_train and X_test using scaler\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # STUDENT TODO END\n",
        "\n",
        "    clf = AdaBoostClassifier(T=10)\n",
        "    # STUDENT TODO START: Now fit clf to the entire training data, i.e., X_train and y_train after feature scaling\n",
        "\n",
        "    clf.fit(X_train,y_train)\n",
        "\n",
        "    # STUDENT TODO END\n",
        "\n",
        "    # STUDENT TODO START: Predict the classes of the datapoints in X_test and return the result\n",
        "    y_predict_test = clf.predict(X_test)\n",
        "    return y_predict_test\n",
        "\n",
        "    # STUDENT TODO END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h20BZarho6w_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "14f211aa-4eb1-4468-a467-fe4f81b01cdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      stp  smax  smin     gbrd  dewp  tmax  dmax  tmin  dmin  hmdy  hmax  \\\n",
              "0     0.9   1.0   0.9    0.000   1.6  -1.1   0.7  -0.9   1.7   5.0   4.0   \n",
              "1    -0.2   0.1   0.0    0.000   0.2   0.0   0.7   0.2   0.4  -1.0   3.0   \n",
              "2     0.0   0.6   0.1  976.697  -0.2   0.5  -0.7   0.8  -1.0  -1.0  -2.0   \n",
              "3     0.2   0.1   0.2    0.000  -0.3   1.5  -0.8   2.3  -0.4  -5.0  -6.0   \n",
              "4     0.0  -0.1  -0.6  896.435  -0.4  -0.3  -0.1  -0.9  -0.1  -2.0   3.0   \n",
              "...   ...   ...   ...      ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "1494  0.2   0.2   0.2 -652.924  -0.1  -1.2  -0.4  -0.4   0.1   6.0   2.0   \n",
              "1495 -0.4  -0.6  -1.2    0.000   0.7   0.9   0.1   0.7   0.3   2.0   0.0   \n",
              "1496 -0.2  -0.3  -0.2    0.000   0.1   0.5   0.0   0.2   0.1   0.0  -1.0   \n",
              "1497  0.4   0.1   0.2    0.000   0.2   0.0   0.1   0.2   0.1  -2.0   0.0   \n",
              "1498  0.1  -0.1  -1.2    0.000   0.0   1.7   0.1   0.5   0.0  -3.0  -3.0   \n",
              "\n",
              "      hmin  wdsp   wdct  gust  \n",
              "0      6.0  -1.1    6.0   0.7  \n",
              "1      2.0   0.8  -13.0  -0.3  \n",
              "2     -1.0   0.8    2.0   0.5  \n",
              "3     -4.0   0.0   23.0   0.3  \n",
              "4      2.0   1.7   36.0   1.3  \n",
              "...    ...   ...    ...   ...  \n",
              "1494   8.0   0.8 -256.0   0.4  \n",
              "1495  -5.0  -1.1  -10.0   0.0  \n",
              "1496  -2.0  -0.1  -21.0   1.0  \n",
              "1497   0.0   0.1    6.0  -0.3  \n",
              "1498  -8.0   2.3    4.0   3.3  \n",
              "\n",
              "[1499 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cfb68c2-51d8-40ce-ab93-ab441cbea543\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stp</th>\n",
              "      <th>smax</th>\n",
              "      <th>smin</th>\n",
              "      <th>gbrd</th>\n",
              "      <th>dewp</th>\n",
              "      <th>tmax</th>\n",
              "      <th>dmax</th>\n",
              "      <th>tmin</th>\n",
              "      <th>dmin</th>\n",
              "      <th>hmdy</th>\n",
              "      <th>hmax</th>\n",
              "      <th>hmin</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>wdct</th>\n",
              "      <th>gust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.6</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>976.697</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>896.435</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-652.924</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-256.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-21.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-1.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1499 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cfb68c2-51d8-40ce-ab93-ab441cbea543')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cfb68c2-51d8-40ce-ab93-ab441cbea543 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cfb68c2-51d8-40ce-ab93-ab441cbea543');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8694794509400303, 0.5841198324165664, 0.40432966290520567, 0.23223773207744705, 0.4944261846641628, 0.2061130285812106, 0.18940988126562866, 0.10097015273177465, 0.05070310624957033, 0.022542469081499737]\n",
            "Correct! You earned 2/2 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    y_test_pred = adaboost_on_dataset()\n",
        "    grader.grade(test_case_id = 'test_adaboost_on_dataset_autograder', answer = y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK4vJh-wDbdC"
      },
      "source": [
        "# **3. [8 pts, 419-optional] XGBoost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdO8f_FWRLt5"
      },
      "source": [
        "## TODOs for this section:\n",
        "- You'll use xgboost library to build a classifier for the above problem. XGBoost is a popular library for gradient boosting, and you can find its documentation [here](https://xgboost.readthedocs.io/en/latest/).\n",
        "- You need to get at least 0.75 accuracy on the test set to receive full credits from the autograder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdOEarsQ8w5L"
      },
      "outputs": [],
      "source": [
        "if NOTEBOOK:\n",
        "  train_df = final_cleaned_df.copy()\n",
        "  test_df = pd.read_csv(\"test_student.csv\").drop(columns=[\"Unnamed: 0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JimlDZbFDsX0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "43d95cb5-9c69-4f8e-b92c-8d7cc1eeee23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        stp  smax  smin      gbrd  dewp  tmax  dmax  tmin  dmin  hmdy  hmax  \\\n",
              "1       0.7   0.7   1.2     0.000   1.4   0.2  -3.2   3.5   1.4   4.0 -19.0   \n",
              "2       0.3   0.3   0.7     0.000   0.5  -0.9   0.4  -1.6   1.4   5.0   5.0   \n",
              "3       0.2   0.2   0.2     0.000   2.9  -1.6   2.9  -1.6   0.5  14.0  14.0   \n",
              "4       0.0   0.1   0.2     0.000  -0.5  -1.1   0.1  -0.5   2.3  -1.0   0.0   \n",
              "5       0.0   0.0   0.0     0.000  -0.2  -0.9  -0.6  -1.5  -0.4   5.0   4.0   \n",
              "...     ...   ...   ...       ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "105195  0.5   0.5   0.9   216.395   1.1   1.9   1.3   0.9   0.5  -4.0  -3.0   \n",
              "105196  0.6   0.8   0.5   335.969   1.2   1.8   0.9   1.5   1.0  -3.0  -1.0   \n",
              "105197 -0.1  -0.2   0.4  1012.706   0.2   3.2   1.1   2.2   0.9 -12.0  -6.0   \n",
              "105198 -0.2   0.1  -0.1  -464.506   0.5   0.0  -0.2   2.1   0.6   0.0  -8.0   \n",
              "105199 -0.3  -0.4  -0.4   583.866  -0.1   1.1   0.5   0.9  -0.1  -3.0  -3.0   \n",
              "\n",
              "        hmin  wdsp  wdct  gust  temp  \n",
              "1        3.0   0.4  -7.0  -0.1   0.0  \n",
              "2        4.0  -1.1  -1.0   0.5   0.0  \n",
              "3        5.0  -0.8   3.0  -1.1   0.0  \n",
              "4       12.0   1.4  14.0   1.7   0.0  \n",
              "5        1.0  -1.1 -11.0  -0.7   0.0  \n",
              "...      ...   ...   ...   ...   ...  \n",
              "105195  -4.0  -0.7  16.0   0.0   1.0  \n",
              "105196  -3.0   0.2 -46.0   0.4   1.0  \n",
              "105197 -15.0   1.3 -49.0   2.9   1.0  \n",
              "105198   2.0   0.7  32.0   1.4   1.0  \n",
              "105199  -6.0  -0.8 -28.0  -1.4   1.0  \n",
              "\n",
              "[104366 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fc9339f-0540-432d-b837-f0d4430ba75e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stp</th>\n",
              "      <th>smax</th>\n",
              "      <th>smin</th>\n",
              "      <th>gbrd</th>\n",
              "      <th>dewp</th>\n",
              "      <th>tmax</th>\n",
              "      <th>dmax</th>\n",
              "      <th>tmin</th>\n",
              "      <th>dmin</th>\n",
              "      <th>hmdy</th>\n",
              "      <th>hmax</th>\n",
              "      <th>hmin</th>\n",
              "      <th>wdsp</th>\n",
              "      <th>wdct</th>\n",
              "      <th>gust</th>\n",
              "      <th>temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-3.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>-1.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>-0.9</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.1</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105195</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>216.395</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105196</th>\n",
              "      <td>0.6</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>335.969</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>-46.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105197</th>\n",
              "      <td>-0.1</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1012.706</td>\n",
              "      <td>0.2</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>-49.0</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105198</th>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-464.506</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>32.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105199</th>\n",
              "      <td>-0.3</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>583.866</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.9</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-28.0</td>\n",
              "      <td>-1.4</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104366 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fc9339f-0540-432d-b837-f0d4430ba75e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fc9339f-0540-432d-b837-f0d4430ba75e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fc9339f-0540-432d-b837-f0d4430ba75e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[  0.7,   0.7,   1.2, ...,   0.4,  -7. ,  -0.1],\n",
              "       [  0.3,   0.3,   0.7, ...,  -1.1,  -1. ,   0.5],\n",
              "       [  0.2,   0.2,   0.2, ...,  -0.8,   3. ,  -1.1],\n",
              "       ...,\n",
              "       [ -0.1,  -0.2,   0.4, ...,   1.3, -49. ,   2.9],\n",
              "       [ -0.2,   0.1,  -0.1, ...,   0.7,  32. ,   1.4],\n",
              "       [ -0.3,  -0.4,  -0.4, ...,  -0.8, -28. ,  -1.4]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if NOTEBOOK:\n",
        "    import xgboost as xgb\n",
        "    from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "    # STUDENT TODO STARTS:\n",
        "    # 1. Fit an xgboost classifier to the training data (train_df, target variable is temp)\n",
        "    display(train_df)\n",
        "    X_train = train_df.iloc[:, :-1].values\n",
        "    display(train_df.iloc[:, :-1].values)\n",
        "    y_train = train_df.iloc[:, -1].values\n",
        "    #display(train_df.iloc[:, -1].values)\n",
        "    model = xgb.XGBClassifier()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    params = {'max_depth': [3, 6, 10, 15],\n",
        "              'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4],\n",
        "              'subsample': np.arange(0.5, 1.0, 0.1),\n",
        "              'colsample_bytree': np.arange(0.5, 1.0, 0.1),\n",
        "              'colsample_bylevel': np.arange(0.5, 1.0, 0.1),\n",
        "              'n_estimators': [100, 250, 500, 750],\n",
        "              'num_class': [10]\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(objective=\"multi:softmax\", tree_method='hist')\n",
        "    clf = RandomizedSearchCV(estimator=model,\n",
        "                             param_distributions=params,\n",
        "                             scoring='accuracy',\n",
        "                             n_iter=25,\n",
        "                             n_jobs=4,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_test_pred = clf.predict(test_df)\n",
        "\n",
        "    \"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    #display(final_cleaned_df)\n",
        "    #display(test_df)\n",
        "\n",
        "    # 2. Obtain the predictions of the trained model on test_df in the variable y_test_pred\n",
        "\n",
        "\n",
        "    # 3. Tune the hyperparameters such that you pass the autograder threshold accuracy of 0.75\n",
        "    y_test_pred = model.predict(test_df.values)\n",
        "\n",
        "    # STUDENT TODO ENDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGs2eXAYnjK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2da7bc7-d3e8-4b53-b955-e02a164ff079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 8/8 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ],
      "source": [
        "# PennGrader Grading Cell\n",
        "if NOTEBOOK:\n",
        "    grader.grade(test_case_id = 'test_xgboost', answer = y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD6VKdQIwcxg"
      },
      "source": [
        "## Submit to Gradescope\n",
        "Congratulations! You've finished the homework. Don't forget to submit your final notebook on [Gradescope](gradescope.com)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "377c3e77380f886ab555d62b93e59a1648fc55affccd8d0220be3281f77f4c6d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}